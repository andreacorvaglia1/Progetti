{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreacorvaglia1/Progetti/blob/master/codice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uts5NI_ZXJbB",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4\n",
        "Andrea Corvaglia 802487"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA81jRbHQFED",
        "colab_type": "text"
      },
      "source": [
        "# Import Librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqgdItb-1FS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsBZtOZC42at",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = VGG16(weights=\"imagenet\", include_top=False)\n",
        "#https://keras.io/applications/#vgg16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV5y4CVtr2Xk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "dd7a3491-8bb7-4a97-9d72-49bb7ce20a9e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVSmiCc0QjPF",
        "colab_type": "text"
      },
      "source": [
        "Si è deciso di vagliare tre possibili tagli, tutti in coda ad un max-pooling per sfruttare la riduzione di dimensionalità. I diversi tagli sono alla fine del primo, terzo e ultimo blocco di convoluzioni. In questo modo è possibile verificare quanto siano simili i task di classificazione rispetto alla rete originale, in base all'altezza del taglio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnCXVl28RQEd",
        "colab_type": "text"
      },
      "source": [
        "# Data Set "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34gWeT66RixV",
        "colab_type": "text"
      },
      "source": [
        "Il dataset proviene da Kaggle (https://www.kaggle.com/slothkong/10-monkey-species#n1017.jpg) e consiste in due file, training e validation. \n",
        "\n",
        "ll dataset è composto da due file, training e validation. Ogni cartella contiene 10 sotto cartelle con le diverse labels delle scimmie indicate come n0 ~ n9, ciascuno corrispondente a una specie provenente dal cladogramma della scimmia di Wikipedia. Le immagini hanno dimensione 400x300 o più grandi e in formato JPEG (quasi 1400 immagini).\n",
        "Il task sarà naturalmente quello di classificare le 10 specie di scimmie.\n",
        "\n",
        "Label mapping:\n",
        "\n",
        "  - n0, alouatta_palliata\n",
        "  - n1, erythrocebus_patas\n",
        "  - n2, cacajao_calvus \n",
        "  - n3, macaca_fuscata   \n",
        "  - n4, cebuella_pygmea\n",
        "  - n5, cebus_capucinus\n",
        "  - n6, mico_argentatus\n",
        "  - n7, saimiri_sciureus \n",
        "  - n8, aotus_nigriceps\n",
        "  - n9, trachypithecus_johnii"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm2hTdXjCc5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import del dataset tramite API di kaggle \n",
        "\n",
        "os.environ['KAGGLEUSERNAME'] = \"andreacorvaglia\" # username from the json file \n",
        "os.environ['KAGGLEKEY'] = \"34f186703895ad8b84a75875c3c7b637\" # key from the json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle\n",
        "!ls -l ~/.kaggle\n",
        "!cat ~/.kaggle/kaggle.json\n",
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli\n",
        "!kaggle datasets download -d slothkong/10-monkey-species\n",
        "!unzip /content/10-monkey-species.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHFkhWslQXrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def features_extractor(isTrain=True, cutDepth = 0):\n",
        "# Funzione che carica le immagini dalle cartelle estraendo l'etichetta, le da in input alla VGG16\n",
        "# caricata dopo averle pre processate e restituisce il dataset pronto alla classificazione.\n",
        "\n",
        "# prende in argomento se si desidera estrarre il training o il validation set e il tipo di taglio\n",
        "# da fare sulla VGG16\n",
        "\n",
        "  x_data = []\n",
        "  y_data = []\n",
        "  # Train o Validation\n",
        "  if isTrain :\n",
        "    p = \"/content/training/training\"\n",
        "  else : p = \"/content/validation/validation/\"\n",
        "  # Altezza del taglio nella rete originale\n",
        "  #lastLayer = [\"block5_conv3\",\"block3_conv3\",\"block1_conv3\"]\n",
        "  lastLayer = [\"block5_pool\",\"block3_pool\",\"block1_pool\"]\n",
        "  model_0 = VGG16(weights=\"imagenet\", include_top=False)\n",
        "  model = Model(inputs=model_0.input, outputs=model_0.get_layer(lastLayer[cutDepth]).output)\n",
        "\n",
        "  subdir= os.listdir(p)\n",
        "  # loop sulle classi\n",
        "  for idx, dirname in enumerate(subdir):\n",
        "      print(dirname)\n",
        "      path=os.path.join(p,dirname)\n",
        "      filenames=os.listdir(path)\n",
        "      # loop sulle immagini\n",
        "      for i, fname in enumerate(filenames):\n",
        "        img_path = os.path.join(path,fname)\n",
        "        # Caricamento delle immagini ridimensionandole ad un 224x224 pixels \n",
        "        img = image.load_img(img_path, target_size=(224, 224))\n",
        "        x = image.img_to_array(img)\n",
        "        # Preprocessing dell'immagine espandendo le dimesioni\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        # e eseguendo i passi con cui si sono ottenuti i pesi che abbiamo caricato per la VGG16\n",
        "        x = preprocess_input(x)\n",
        "        features = np.array(model.predict(x)).flatten()\n",
        "\n",
        "        x_data.append(features)\n",
        "        y_data.append(int(list(dirname)[1]))\n",
        "\n",
        "  return np.array(x_data), np.array(y_data)\n",
        "\n",
        "\n",
        "def report (classifier):\n",
        "# funzione che valuta le perfomance del classificatore in argomento \n",
        "  labels=classifier.predict(x_val)\n",
        "  print(classification_report(labels, y_val))\n",
        "  print(\"L'accuracy sul validation set è: \\n\")\n",
        "  print(accuracy_score(labels, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLOdaWEWiuNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "np.save(\"/content/drive/My Drive/Assignment 4/x_train\", x_train)\n",
        "np.save(\"/content/drive/My Drive/Assignment 4/y_train\", y_train)\n",
        "np.save(\"/content/drive/My Drive/Assignment 4/x_val\", x_val)\n",
        "np.save(\"/content/drive/My Drive/Assignment 4/y_val\", y_val)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKBlWQKmBCRW",
        "colab_type": "code",
        "outputId": "52d6e83d-1e14-44fe-ae90-df5f86ab892f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "pd.value_counts(y_train).plot(kind='bar',title =\"Frequenze assolute classi\")\n",
        "# Le classi risultano per lo più ben distribuite"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f72f6a4ecc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEFCAYAAAAYKqc0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNehfAY+cfN1uWDRwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4eC8Y_VVo0I",
        "colab_type": "text"
      },
      "source": [
        "# Classificazione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-SJxEwAVt9z",
        "colab_type": "text"
      },
      "source": [
        "Per la parte finale di classificazione si è scelto di confrontare tre algoritmi:\n",
        "  - Linear SVC \n",
        "  - Random Forest\n",
        "  - K-Nearest Neighbourhood   \n",
        "\n",
        "Per quanto riguarda invece la scelta degli iper-parametri dei modelli si è usata una grid search implementata con sklearn.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr9tLbQS2WsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "# defining parameter range \n",
        "param_grid = {'C': [0.1, 1, 10]}  \n",
        "  \n",
        "grid = GridSearchCV(LinearSVC(), param_grid, refit = True, verbose = 3) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlehIA-mrat7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "d66db18a-91be-447f-d16f-905f7f9a028b"
      },
      "source": [
        "grid.fit(x_train, y_train)  \n",
        "\n",
        "#print(clf.coef_)\n",
        "#print(clf.intercept_)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ............................... C=0.1, score=0.992, total=   3.1s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.962, total=   5.4s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.975, total=   4.2s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.992, total=   5.1s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.962, total=   6.4s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.975, total=   3.6s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.992, total=   6.0s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.962, total=   6.1s\n",
            "[CV] C=10 ............................................................\n",
            "[CV] ................................ C=10, score=0.975, total=   3.5s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   43.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
              "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                                 fit_intercept=True, intercept_scaling=1,\n",
              "                                 loss='squared_hinge', max_iter=1000,\n",
              "                                 multi_class='ovr', penalty='l2',\n",
              "                                 random_state=None, tol=0.0001, verbose=0),\n",
              "             iid='warn', n_jobs=None, param_grid={'C': [0.1, 1, 10]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3F_VM95w2nK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b9a4eb1-4aee-41c0-b342-fafc2def7c29"
      },
      "source": [
        "# Scelta del miglior taglio sul modello originale \n",
        "\n",
        "import gc\n",
        "# viene usato \"gc\" insieme a \"del\" per conservare memoria sulla ram\n",
        "acc = [] # lista delle accuracy\n",
        "for cut in range(3):\n",
        "    print(\"Tentativo: \"+str(cut))\n",
        "    # Estrazione dei dati processati attraverso la rete taglia alla profondità \"cut\"\n",
        "    x_train, y_train = features_extractor(isTrain=True,cutDepth=cut)\n",
        "    x_val, y_val = features_extractor(isTrain=False,cutDepth=cut)\n",
        "    # classificazione col modello tradizionale\n",
        "    clf.fit(x_train, y_train)  \n",
        "    labels=clf.predict(x_val)\n",
        "    # print dei risulrari\n",
        "    print(classification_report(labels, y_val))\n",
        "    print(\"L'accuracy sul validation set è: \\n\")\n",
        "    print(accuracy_score(labels, y_val))\n",
        "    acc.append(accuracy_score(labels, y_val))\n",
        "    # liberazione della memoria\n",
        "    del  x_train, y_train, x_val, y_val\n",
        "    gc.collect()\n",
        "\n",
        "acc = np.array(acc)\n",
        "bestCut = argmax(acc)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tentativo: 0\n",
            "n5\n",
            "n3\n",
            "n9\n",
            "n0\n",
            "n6\n",
            "n4\n",
            "n1\n",
            "n8\n",
            "n7\n",
            "n2\n",
            "n5\n",
            "n3\n",
            "n9\n",
            "n0\n",
            "n6\n",
            "n4\n",
            "n1\n",
            "n8\n",
            "n7\n",
            "n2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95        29\n",
            "           1       1.00      0.97      0.98        29\n",
            "           2       0.96      1.00      0.98        26\n",
            "           3       1.00      1.00      1.00        30\n",
            "           4       1.00      0.96      0.98        27\n",
            "           5       0.96      0.96      0.96        28\n",
            "           6       0.96      1.00      0.98        25\n",
            "           7       0.96      0.96      0.96        28\n",
            "           8       0.96      0.96      0.96        27\n",
            "           9       0.88      1.00      0.94        23\n",
            "\n",
            "    accuracy                           0.97       272\n",
            "   macro avg       0.97      0.97      0.97       272\n",
            "weighted avg       0.97      0.97      0.97       272\n",
            "\n",
            "L'accuracy sul validation set è: \n",
            "\n",
            "0.9705882352941176\n",
            "Tentativo: 1\n",
            "n5\n",
            "n3\n",
            "n9\n",
            "n0\n",
            "n6\n",
            "n4\n",
            "n1\n",
            "n8\n",
            "n7\n",
            "n2\n",
            "n5\n",
            "n3\n",
            "n9\n",
            "n0\n",
            "n6\n",
            "n4\n",
            "n1\n",
            "n8\n",
            "n7\n",
            "n2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.78      0.64        18\n",
            "           1       0.71      0.69      0.70        29\n",
            "           2       0.96      0.90      0.93        29\n",
            "           3       0.83      0.71      0.77        35\n",
            "           4       0.81      0.75      0.78        28\n",
            "           5       0.50      0.50      0.50        28\n",
            "           6       0.88      0.72      0.79        32\n",
            "           7       0.64      0.78      0.71        23\n",
            "           8       0.81      0.85      0.83        26\n",
            "           9       0.69      0.75      0.72        24\n",
            "\n",
            "    accuracy                           0.74       272\n",
            "   macro avg       0.74      0.74      0.74       272\n",
            "weighted avg       0.75      0.74      0.74       272\n",
            "\n",
            "L'accuracy sul validation set è: \n",
            "\n",
            "0.7389705882352942\n",
            "Tentativo: 2\n",
            "n5\n",
            "n3\n",
            "n9\n",
            "n0\n",
            "n6\n",
            "n4\n",
            "n1\n",
            "n8\n",
            "n7\n",
            "n2\n",
            "n5\n",
            "n3\n",
            "n9\n",
            "n0\n",
            "n6\n",
            "n4\n",
            "n1\n",
            "n8\n",
            "n7\n",
            "n2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gn8aWvluzaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=500, max_depth=4).fit(X_train, y_train)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6wpzWRmvmuy",
        "colab_type": "text"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrxY0w0mx8yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=10)\n",
        "neigh.fit(x_train, y_train)  \n",
        "labels=neigh.predict(x_val)\n",
        "print(classification_report(labels, y_val))\n",
        "print(\"L'accuracy sul validation set è: \\n\")\n",
        "print(accuracy_score(labels, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}